{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Fl7zUUWBV6mS"
   },
   "outputs": [],
   "source": [
    "#código de inicio\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyhlZPUEwufO"
   },
   "source": [
    "# <img style=\"float: left; padding-right: 20px; width: 100px\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Escudo_de_la_Pontificia_Universidad_Cat%C3%B3lica_de_Chile.svg/1920px-Escudo_de_la_Pontificia_Universidad_Cat%C3%B3lica_de_Chile.svg.png\"> MCD3020 - Introducción a Ciencia de Datos\n",
    "**Pontificia Universidad Católica de Chile**<br>\n",
    "**Magíster en Ciencia de Datos**<br>\n",
    "**2022**<br>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFn7QeLu3xOO"
   },
   "source": [
    "# Tarea 1: Extracción de datos mediante webscraping.\n",
    "\n",
    "***\n",
    "## Instrucciones Generales:\n",
    "- Esta Tarea debe ser desarrollada completamente en lenguaje de programación Python, en este mismo Notebook.\n",
    "- El Notebook debe estar  ordenado, seguir buenas prácticas de escritura y programación, e incluir comentarios o celdas de markdown suficientes para explicar claramente todos lo códigos computacionales.\n",
    "- El Notebook ya contiene algunas celdas marcadas con el comentario `#código de inicio`. Estas celdas han sido incluidas como ayuda para el desarrollo de la Tarea, y pueden ser ejecutadas tal como están.\n",
    "- Las celdas marcadas como `#completar código` tienen un código parcial que debe ser completado para poder ser ejecutado. Ud debe agregar todas las líneas o bloques de código necesarios para desarrollar correctamente cada punto de la tarea. También puede eliminar estas celdas y partir el código desde cero si le resulta más conveniente.\n",
    "- Para el desarrollo de cada pregunta, se sugiere agregar las celdas de código y/o markdown necesarias bajo el enunciado de la misma.\n",
    "- Asegúrese de guardar los cambios en su Notebook antes de entregarlo.\n",
    "\n",
    "***\n",
    "## Introducción.\n",
    "\n",
    "Hace ya casi 10 años, el trabajo de científico de datos fue catalogado por Harvard Bussiness Review como \"el trabajo más atractivo del siglo XXI\" [(Davenport & Patil 2012)](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century). Desde entonces, se ha comprobado un aumento constante de la demanda por profesionales expertos datos, y se espera que tanto la creación de puestos trabajos como los salarios sigan al alza en los próximos años. Los siguienes artículos de prensa y difusión ilustran esta situación:\n",
    "\n",
    "https://www.smithhanley.com/2022/01/04/data-science-in-2022/\n",
    "https://www.bbva.com/es/big-data-la-demanda-de-talento-experto-sigue-creciendo/\n",
    "\n",
    "Los estudios citados hacen referencia a mercados laborales en Europa y Estados Unidos. Suponga que ud.está a cargo del desarrollo de un estudio del mercado laboral de científicos de datos en latinoamérica, para lo cual necesita construir una base de datos con las ofertas de trabajo publicadas en distintos países de la región.\n",
    "\n",
    "El objetivo de esta tarea es usar técnicas de webscrapping para extraer datos de ofertas para científicos de datos publicadas en un portal abierto de empleos (www.linkedin.com/jobs).\n",
    "\n",
    "NOTA: Este trabajo fue inspirado de [Tutorial](https://www.youtube.com/watch?v=eN_3d4JrL_w&ab_channel=IzzyAnalytics)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Ingrese a la página web de www.linkedin.com/jobs, haga click en el botón `Buscar Empleos` y realice una búsqueda de empleos para *data scientist* en la capital de su país (u otra ciudad de su interés). Inspeccione y analice el código fuente de la página de resultados, para entender la estructura de su código HTML. [1 punto]\n",
    "\n",
    "En base a su inspección del código HTML, responda: ¿Qué elemento del código le permite llegar exactamente a la lista de anuncios de empleo?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respuesta\n",
    "\n",
    "#### Probando con sesión iniciada\n",
    "Inspeccionando el código HTML en linkedin, el elemento <*ul class=\"scaffold-layout__list-container\"*> permite obtener directamente el listado de anuncios de empleo, una vez realizada la búsqueda.\n",
    "\n",
    "#### Probando en modo incógnito (sin cookies)\n",
    "Inspeccionando el código HTML en linkedin, el elemento <*ul class=\"jobs-search__results-list\"*> permite obtener directamente el listado de anuncios de empleo, una vez realizada la búsqueda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Extraiga la lista de anuncios de trabajo arrojados por su búsqueda en Linkedin.  [1 punto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.linkedin.com/jobs/search/?keywords=data scientist&location=santiago de chile'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#complete este código\n",
    "position = 'data scientist'\n",
    "job_location = 'santiago de chile'\n",
    "url_search = 'https://www.linkedin.com/jobs/search/?keywords=%s&location=%s'%(position, job_location)\n",
    "url_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1201,
     "status": "ok",
     "timestamp": 1663750896239,
     "user": {
      "displayName": "Constanza MOLINA CATRICHEO",
      "userId": "11792009633930116914"
     },
     "user_tz": -120
    },
    "id": "6jJqLmYP3Ux5",
    "outputId": "9aae26a0-53de-4193-be82-4f376900f754"
   },
   "outputs": [],
   "source": [
    "#código de inicio\n",
    "\n",
    "#Para evitar que la página web piense que usted es un bot, al realizar el request utilice algunos de los siguientes encabezados: \n",
    "#head = {'User-Agent': 'Mozilla/5.0'}\n",
    "#head = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36'}\n",
    "head = {'user-agent':'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Mobile Safari/537.36'}\n",
    "#head = {'user-agent':'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Mobile Safari/537.36'}\n",
    "#head = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "#complete este código\n",
    "response = requests.get(url_search, headers=head)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "joblist = soup.find('ul', class_ = 'jobs-search__results-list')\n",
    "alljobs = joblist.find_all('li')\n",
    "\n",
    "print(len(alljobs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: En el código HTML fuente, los objetos de la lista con tag <*li*> no tenían clase, por lo que solo busqué por su tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Seleccione por ahora sólo el primer anuncio de la lista, y extraiga la información de:  título del trabajo, nombre de la compañía, localización, y URL del anuncio  [2 puntos].\n",
    "\n",
    "Nota: Por localización se entiende la ciudad, comuna o municipio indicado en el anuncio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location: Santiago, Santiago Metropolitan Region, Chile\n",
      "Title: Data Scientist\n",
      "Company: NeuralWorks\n",
      "Job url: https://cl.linkedin.com/jobs/view/data-scientist-at-neuralworks-3623665055?refId=qwPPNYJgg5duO7AWiBeZTA%3D%3D&trackingId=%2BEntdOy5ylPU7JA2m7e2kQ%3D%3D&position=1&pageNum=0&trk=public_jobs_jserp-result_search-card\n"
     ]
    }
   ],
   "source": [
    "#complete este código\n",
    "\n",
    "job = alljobs[0]\n",
    "\n",
    "div = job.div\n",
    "base_info_div = div.find('div', class_='base-search-card__info')\n",
    "\n",
    "location = base_info_div.find('span', class_='job-search-card__location').text.strip()\n",
    "title = base_info_div.h3.text.strip()\n",
    "company = base_info_div.h4.a.text.strip()\n",
    "job_url = div.a.get('href')\n",
    "\n",
    "print(f'Location: {location}')\n",
    "print(f'Title: {title}')\n",
    "print(f'Company: {company}')\n",
    "print(f'Job url: {job_url}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. En base a los puntos anteriores, programe una rutina para extraer la información de localización,  título del trabajo, nombre de la compañía, localización, y URL del anuncio para todos los trabajos arrojados por su búsqueda de Linkedin, y almacenar los datos en un dataframe de pandas  [3 puntos]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5x/tlp5fd614dv9y_wn8nmtqv4rqq_frn/T/ipykernel_27168/653190867.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_jobs = df_jobs.append(extract_job_offers(alljobs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Santiago, Santiago Metropolitan Region, Chile</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NeuralWorks</td>\n",
       "      <td>https://cl.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Santiago, Santiago Metropolitan Region, Chile</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>BICE VIDA</td>\n",
       "      <td>https://cl.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Providencia, Santiago Metropolitan Region, Chile</td>\n",
       "      <td>Data Scientist - Career</td>\n",
       "      <td>Equifax</td>\n",
       "      <td>https://cl.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Santiago, Santiago Metropolitan Region, Chile</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Michael Page</td>\n",
       "      <td>https://cl.linkedin.com/jobs/view/machine-lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Santiago Metropolitan Area</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>MyDNA</td>\n",
       "      <td>https://cl.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Santiago Metropolitan Area</td>\n",
       "      <td>Data Scientist- Remoto</td>\n",
       "      <td>Michael Page</td>\n",
       "      <td>https://cl.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Santiago, Santiago Metropolitan Region, Chile</td>\n",
       "      <td>#318 Data Scientist</td>\n",
       "      <td>The Bridge Social</td>\n",
       "      <td>https://cl.linkedin.com/jobs/view/%23318-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Providencia, Santiago Metropolitan Region, Chile</td>\n",
       "      <td>Data Scientist - Career</td>\n",
       "      <td>Equifax</td>\n",
       "      <td>https://cl.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Santiago, Santiago Metropolitan Region, Chile</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>COSMOS Save Energy</td>\n",
       "      <td>https://cl.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Las Condes, Santiago Metropolitan Region, Chile</td>\n",
       "      <td>Digital Data Scientist - Las Condes</td>\n",
       "      <td>GRUPO PROGESTION</td>\n",
       "      <td>https://cl.linkedin.com/jobs/view/digital-data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Location  \\\n",
       "0     Santiago, Santiago Metropolitan Region, Chile   \n",
       "1     Santiago, Santiago Metropolitan Region, Chile   \n",
       "2  Providencia, Santiago Metropolitan Region, Chile   \n",
       "3     Santiago, Santiago Metropolitan Region, Chile   \n",
       "4                        Santiago Metropolitan Area   \n",
       "5                        Santiago Metropolitan Area   \n",
       "6     Santiago, Santiago Metropolitan Region, Chile   \n",
       "7  Providencia, Santiago Metropolitan Region, Chile   \n",
       "8     Santiago, Santiago Metropolitan Region, Chile   \n",
       "9   Las Condes, Santiago Metropolitan Region, Chile   \n",
       "\n",
       "                                 Title             Company  \\\n",
       "0                       Data Scientist         NeuralWorks   \n",
       "1                       Data Scientist           BICE VIDA   \n",
       "2              Data Scientist - Career             Equifax   \n",
       "3            Machine Learning Engineer        Michael Page   \n",
       "4                       Data Scientist               MyDNA   \n",
       "5               Data Scientist- Remoto        Michael Page   \n",
       "6                  #318 Data Scientist   The Bridge Social   \n",
       "7              Data Scientist - Career             Equifax   \n",
       "8                       Data Scientist  COSMOS Save Energy   \n",
       "9  Digital Data Scientist - Las Condes    GRUPO PROGESTION   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://cl.linkedin.com/jobs/view/data-scienti...  \n",
       "1  https://cl.linkedin.com/jobs/view/data-scienti...  \n",
       "2  https://cl.linkedin.com/jobs/view/data-scienti...  \n",
       "3  https://cl.linkedin.com/jobs/view/machine-lear...  \n",
       "4  https://cl.linkedin.com/jobs/view/data-scienti...  \n",
       "5  https://cl.linkedin.com/jobs/view/data-scienti...  \n",
       "6  https://cl.linkedin.com/jobs/view/%23318-data-...  \n",
       "7  https://cl.linkedin.com/jobs/view/data-scienti...  \n",
       "8  https://cl.linkedin.com/jobs/view/data-scienti...  \n",
       "9  https://cl.linkedin.com/jobs/view/digital-data...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#complete este código\n",
    "df_jobs = pd.DataFrame(columns = ['Location', 'Title', 'Company', 'Url'])\n",
    "\n",
    "\n",
    "def extract_job_offer_data(job):\n",
    "    '''\n",
    "    Funcion que obtiene de input un objeto de tipo tag de BeautifulSoup y retorna los atributos buscados\n",
    "    '''\n",
    "    return {\n",
    "        'Location': job.div.find('div', class_='base-search-card__info').find('span', class_='job-search-card__location').text.strip(),\n",
    "        'Title': job.div.find('div', class_='base-search-card__info').h3.text.strip(),\n",
    "        'Company': job.div.find('div', class_='base-search-card__info').h4.a.text.strip(),\n",
    "        'Url': job.div.a.get('href')\n",
    "    }\n",
    "\n",
    "def extract_job_offers(jobs_list):\n",
    "    # Iteramos sobre la lista\n",
    "    data = list()\n",
    "    for j in range(len(jobs_list)):\n",
    "        job_offer = extract_job_offer_data(jobs_list[j])\n",
    "        data.append(job_offer)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "df_jobs = df_jobs.append(extract_job_offers(alljobs))\n",
    "df_jobs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Exporte su dataframe a un archivo en formato .csv.  [1 punto]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.to_csv(f'{position}_{job_location}_jobs.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. ¿Cuántas ofertas de empleo contiene su dataframe, y cuántos resultados hay en total en la búsqueda de Linkedin? Comente sobre las diferencias o coincidencias, y explique qué debería hacer para extraer todos los resultados disponibles en Linkedin (en palabras, no es necesario implementarlo)  [1 punto]\n",
    "\n",
    "Hint: Verifique el número de páginas de resultados, y la URL correspondiente a cada una de ellas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ofertas de empleo del dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ofertas en DataFrame: 25\n"
     ]
    }
   ],
   "source": [
    "total_ofertas = len(df_jobs)\n",
    "print(f\"Total ofertas en DataFrame: {total_ofertas}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Total ofertas**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la sesión iniciada, hay un total de 1.813 resultados referentes a ofertas laborales que hay en Santiago de Chile. Si no mantenemos la sesión iniciada, el total de ofertas laborales en Linkedin no es claro, ya que se redondea este a 1000 y la url, pese a ser paginada, siempre redirige al primer resultado, es decir los primeros 25 empleos. Es importante considerar el uso de un bot para tales cases, tales como Selenium u otras tecnologías.\n",
    "\n",
    "Dado que utilizamos BeautifulSoup para scraping y no utilizamos una cookie, los resultados que se obtienen en la *request* son acorde a no tener una sesión iniciada en Linkedin, por lo cual es coherente que nuestro DataFrame contenga los mismos datos que aparecen en el sitio, al realizar la búsqueda sin iniciar sesión."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cómo extraer todos los resultados disponibles**\n",
    "\n",
    "Para extraer todos los resultados disponibles, lo primero sería revisar el archivo *robots.txt* del sitio, a modo de entender las condiciones necesarias para que el scraping sea efectivo. Luego de esto, lo que conviene es utilizar alguna tecnología para poder iniciar sesión en Linkedin y desde ahí obtener los resultados paginados. Una tecnología recomendada para esto es levantar un Bot con *Selenium*. Una vez realizado esto, conviene iterar por la cantidad de resultados paginados según la url que Linkedin ofrece. De esta forma, se debería iterar por realizando el mismo proceso que nosotros hicimos, pero agregando el parámetro desde la segunda iteración `start=i*25` siendo `i` el número de la iteración y la página. De esta forma, se va agregando el parámetro acorde a lo siguiente:\n",
    "\n",
    "* iteración 0: no se agrega el parámetro\n",
    "* iteración 1: `start=25`\n",
    "* iteración 2: `start=50`\n",
    "* iteración 3: `start=75`\n",
    "* iteración 4: `start=100`\n",
    "..\n",
    "..\n",
    "..\n",
    "..\n",
    "\n",
    "*Cabe recordar que Python comienza las indexaciones desde el número 0 en adelante.\n",
    "\n",
    "Por último, se deben guardar todos los resultados en una estructura de datos y, finalmente, llenar el DataFrame con la data.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
