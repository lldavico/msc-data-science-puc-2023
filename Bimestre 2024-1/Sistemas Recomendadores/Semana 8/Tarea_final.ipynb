{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NC-ceGb8LRLT"
   },
   "source": [
    "# Tarea 4 - MAN3160"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mACJbcW8T35p"
   },
   "source": [
    "\n",
    "\n",
    "**Profesor**: Denis Parra\n",
    "\n",
    "**Ayudante**: Álvaro Labarca.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcqqkI9yZ2tL"
   },
   "source": [
    "Esta tarea esta dividida en dos secciones. En la primera se evaluarán métodos de recomendación con métricas que no están enfocadas hacia la exactitud de las recomendaciones y la segunda sección es de utilizar Gru4Rec para generar un modelo de recomendación secuencial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sección 1 - Métricas Beyond-Accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora, hemos visto una gran cantidad de formas de evaluar sistemas recomendadores, métricas de error, métricas de ranking, métricas de presición, etc.\n",
    "\n",
    "Estas métricas se enfocan principalmente en evaluar si las recomendaciones entregadas se ajustan a las preferencias reales de los usuarios, ya sea prediciendo calificaciones cercanas a las dadas por el usuario o bien, recomendando elementos con los que el usuario realmente interactuó.\n",
    "\n",
    "Sin embargo, ciertos estudios, como los llevados a cabo por Ziegler et al. (2005), Vargas y Castell (2011) y Lathia et al. (2010) proponen evaluar modelos con métricas denominadas en la literatura como métricas Beyond-Accuracy. Este tipo de métricas se enfocan en evaluar características de las recomendaciones que pueden llevar a una mayor satisfacción para el usuario o que se ajusten mejor a los objetivos de las plataformas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En clases se mencionó dos de estas métricas: **Diversidad:** La cual mide qué tan \"distintas\" entre sí son las recomendaciones entregadas por el sistema y **novedad**, la cual busca que el sistema recomiende ítems que sean \"novedosos\", es decir, que recomiende ítems que sean poco probables que el usuario ya conozca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas métricas han sido definidas de distintas maneras por distintos autores. Para el desarrollo de esta tarea, vamos a utilizar la **Diversidad de Ziegler** y la **Novedad de Vargas**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta sección, vamos a trabajar con el dataset de MovieLens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPCUqeZNb2-D",
    "outputId": "55d2ce6a-4951-44c7-b592-206030b24efe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /opt/homebrew/lib/python3.11/site-packages (3.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: zipfile36 in /opt/homebrew/lib/python3.11/site-packages (0.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: implicit in /opt/homebrew/lib/python3.11/site-packages (0.7.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/homebrew/lib/python3.11/site-packages (from implicit) (1.23.5)\n",
      "Requirement already satisfied: scipy>=0.16 in /opt/homebrew/lib/python3.11/site-packages (from implicit) (1.10.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/lib/python3.11/site-packages (from implicit) (4.65.0)\n",
      "Requirement already satisfied: threadpoolctl in /opt/homebrew/lib/python3.11/site-packages (from implicit) (3.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "/Users/ldavico/.pyenv/versions/3.11.2/bin/python: No module named wget\n",
      "Requirement already satisfied: deepctr-torch in /opt/homebrew/lib/python3.11/site-packages (0.2.9)\n",
      "Requirement already satisfied: torch>=1.2.0 in /opt/homebrew/lib/python3.11/site-packages (from deepctr-torch) (2.1.1)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from deepctr-torch) (4.65.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.11/site-packages (from deepctr-torch) (1.2.2)\n",
      "Requirement already satisfied: tensorflow in /opt/homebrew/lib/python3.11/site-packages (from deepctr-torch) (2.16.1)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.2.0->deepctr-torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.2.0->deepctr-torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.2.0->deepctr-torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.2.0->deepctr-torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.2.0->deepctr-torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.2.0->deepctr-torch) (2023.9.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn->deepctr-torch) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn->deepctr-torch) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn->deepctr-torch) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn->deepctr-torch) (3.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/ldavico/Library/Python/3.11/lib/python/site-packages (from tensorflow->deepctr-torch) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (67.6.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (2.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (3.1.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (0.36.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow->deepctr-torch) (0.40.0)\n",
      "Requirement already satisfied: rich in /opt/homebrew/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow->deepctr-torch) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/homebrew/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow->deepctr-torch) (0.0.7)\n",
      "Requirement already satisfied: optree in /opt/homebrew/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow->deepctr-torch) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow->deepctr-torch) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow->deepctr-torch) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow->deepctr-torch) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow->deepctr-torch) (2022.12.7)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow->deepctr-torch) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow->deepctr-torch) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow->deepctr-torch) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch>=1.2.0->deepctr-torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.11/site-packages (from sympy->torch>=1.2.0->deepctr-torch) (1.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow->deepctr-torch) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow->deepctr-torch) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow->deepctr-torch) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tensorflow in /opt/homebrew/lib/python3.11/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/ldavico/Library/Python/3.11/lib/python/site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (67.6.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (3.1.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: rich in /opt/homebrew/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/homebrew/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in /opt/homebrew/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/homebrew/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: lightfm in /opt/homebrew/lib/python3.11/site-packages (1.17)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from lightfm) (1.23.5)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/homebrew/lib/python3.11/site-packages (from lightfm) (1.10.1)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from lightfm) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.11/site-packages (from lightfm) (1.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->lightfm) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->lightfm) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->lightfm) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->lightfm) (2022.12.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn->lightfm) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn->lightfm) (3.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wget\n",
    "!pip install zipfile36\n",
    "!pip3 install implicit --upgrade\n",
    "!python -m wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!pip install deepctr-torch\n",
    "!pip install tensorflow\n",
    "!pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /opt/homebrew/lib/python3.11/site-packages (3.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: zipfile36 in /opt/homebrew/lib/python3.11/site-packages (0.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "--2024-05-14 21:34:45--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
      "Resolviendo files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Conectando con files.grouplens.org (files.grouplens.org)[128.101.65.152]:80... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 200 OK\n",
      "Longitud: 4924029 (4.7M) [application/zip]\n",
      "Grabando a: «ml-100k.zip.2»\n",
      "\n",
      "ml-100k.zip.2       100%[===================>]   4.70M   804KB/s    en 6.4s    \n",
      "\n",
      "2024-05-14 21:34:52 (751 KB/s) - «ml-100k.zip.2» guardado [4924029/4924029]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install wget\n",
    "!pip install zipfile36\n",
    "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"ml-100k.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Pueden importar las librerías que estimen necesarias.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import implicit\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from deepctr_torch.inputs import SparseFeat, VarLenSparseFeat\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import lightfm\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import cross_validation\n",
    "from lightfm.evaluation import auc_score, precision_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_train = 'ml-100k'\n",
    "\n",
    "# Generamos los títulos de las columnas del archivo items.\n",
    "\n",
    "columns = ['itemid', 'title', 'release_date', 'video_release_date', \\\n",
    "           'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation', \\\n",
    "           'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', \\\n",
    "           'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', \\\n",
    "           'Thriller', 'War', 'Western']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "10N9GHcw5AeV",
    "outputId": "323f55a2-7cb4-470e-dcf3-ce14747f88a3"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{dir_train}/u.data',\n",
    "                         sep='\\t',\n",
    "                         names=['userid', 'itemid', 'rating', 'timestamp'],\n",
    "                         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = pd.read_csv(f'{dir_train}/u.item',\n",
    "                        sep='|',\n",
    "                        index_col=0,\n",
    "                        names = columns,\n",
    "                        header=None,\n",
    "                        encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de vector latente basado en contenido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la métrica de Diversidad de Ziegler, necesitamos un método para calcular la distancia entre dos ítems. Para esto, usaremos la información de contenido de ítems proporcionada por MovieLens para generar vectores latentes para cada ítem. En específico, utilizaremos la información del género de las películas y el año en que fueron estrenadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>IMDb_URL</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title release_date  video_release_date  \\\n",
       "itemid                                                       \n",
       "1        Toy Story (1995)  01-Jan-1995                 NaN   \n",
       "2        GoldenEye (1995)  01-Jan-1995                 NaN   \n",
       "3       Four Rooms (1995)  01-Jan-1995                 NaN   \n",
       "4       Get Shorty (1995)  01-Jan-1995                 NaN   \n",
       "5          Copycat (1995)  01-Jan-1995                 NaN   \n",
       "\n",
       "                                                 IMDb_URL  unknown  Action  \\\n",
       "itemid                                                                       \n",
       "1       http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n",
       "2       http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
       "3       http://us.imdb.com/M/title-exact?Four%20Rooms%...        0       0   \n",
       "4       http://us.imdb.com/M/title-exact?Get%20Shorty%...        0       1   \n",
       "5       http://us.imdb.com/M/title-exact?Copycat%20(1995)        0       0   \n",
       "\n",
       "        Adventure  Animation  Children  Comedy  ...  Fantasy  Film-Noir  \\\n",
       "itemid                                          ...                       \n",
       "1               0          1         1       1  ...        0          0   \n",
       "2               1          0         0       0  ...        0          0   \n",
       "3               0          0         0       0  ...        0          0   \n",
       "4               0          0         0       1  ...        0          0   \n",
       "5               0          0         0       0  ...        0          0   \n",
       "\n",
       "        Horror  Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "itemid                                                                     \n",
       "1            0        0        0        0       0         0    0        0  \n",
       "2            0        0        0        0       0         1    0        0  \n",
       "3            0        0        0        0       0         1    0        0  \n",
       "4            0        0        0        0       0         0    0        0  \n",
       "5            0        0        0        0       0         1    0        0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, se obtiene el año de estreno a partir de la columna 'release_date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items['release_date'] = pd.to_datetime(df_items['release_date'], format='%d-%b-%Y')\n",
    "\n",
    "# Extract year and create a new column 'year'\n",
    "df_items['year'] = df_items['release_date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la escala de la información del año es mucho más elevada que la información de género, usamos una normalización de Z-score para generar la columna 'normalized_year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df_items['year'].mean()\n",
    "std = df_items['year'].std()\n",
    "\n",
    "df_items['normalized_year'] = (df_items['year'] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>IMDb_URL</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>...</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>year</th>\n",
       "      <th>normalized_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>0.393860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>0.393860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>0.393860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>0.393860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>0.393860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>Mat' i syn (1997)</td>\n",
       "      <td>1998-02-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Mat%27+i+syn+...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>0.604334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>B. Monkey (1998)</td>\n",
       "      <td>1998-02-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?B%2E+Monkey+(...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>0.604334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>Sliding Doors (1998)</td>\n",
       "      <td>1998-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/Title?Sliding+Doors+(1998)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>0.604334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>You So Crazy (1994)</td>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?You%20So%20Cr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.323703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>Scream of Stone (Schrei aus Stein) (1991)</td>\n",
       "      <td>1996-03-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Schrei%20aus%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>0.464018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title release_date  \\\n",
       "itemid                                                           \n",
       "1                                Toy Story (1995)   1995-01-01   \n",
       "2                                GoldenEye (1995)   1995-01-01   \n",
       "3                               Four Rooms (1995)   1995-01-01   \n",
       "4                               Get Shorty (1995)   1995-01-01   \n",
       "5                                  Copycat (1995)   1995-01-01   \n",
       "...                                           ...          ...   \n",
       "1678                            Mat' i syn (1997)   1998-02-06   \n",
       "1679                             B. Monkey (1998)   1998-02-06   \n",
       "1680                         Sliding Doors (1998)   1998-01-01   \n",
       "1681                          You So Crazy (1994)   1994-01-01   \n",
       "1682    Scream of Stone (Schrei aus Stein) (1991)   1996-03-08   \n",
       "\n",
       "        video_release_date                                           IMDb_URL  \\\n",
       "itemid                                                                          \n",
       "1                      NaN  http://us.imdb.com/M/title-exact?Toy%20Story%2...   \n",
       "2                      NaN  http://us.imdb.com/M/title-exact?GoldenEye%20(...   \n",
       "3                      NaN  http://us.imdb.com/M/title-exact?Four%20Rooms%...   \n",
       "4                      NaN  http://us.imdb.com/M/title-exact?Get%20Shorty%...   \n",
       "5                      NaN  http://us.imdb.com/M/title-exact?Copycat%20(1995)   \n",
       "...                    ...                                                ...   \n",
       "1678                   NaN  http://us.imdb.com/M/title-exact?Mat%27+i+syn+...   \n",
       "1679                   NaN  http://us.imdb.com/M/title-exact?B%2E+Monkey+(...   \n",
       "1680                   NaN      http://us.imdb.com/Title?Sliding+Doors+(1998)   \n",
       "1681                   NaN  http://us.imdb.com/M/title-exact?You%20So%20Cr...   \n",
       "1682                   NaN  http://us.imdb.com/M/title-exact?Schrei%20aus%...   \n",
       "\n",
       "        unknown  Action  Adventure  Animation  Children  Comedy  ...  Horror  \\\n",
       "itemid                                                           ...           \n",
       "1             0       0          0          1         1       1  ...       0   \n",
       "2             0       1          1          0         0       0  ...       0   \n",
       "3             0       0          0          0         0       0  ...       0   \n",
       "4             0       1          0          0         0       1  ...       0   \n",
       "5             0       0          0          0         0       0  ...       0   \n",
       "...         ...     ...        ...        ...       ...     ...  ...     ...   \n",
       "1678          0       0          0          0         0       0  ...       0   \n",
       "1679          0       0          0          0         0       0  ...       0   \n",
       "1680          0       0          0          0         0       0  ...       0   \n",
       "1681          0       0          0          0         0       1  ...       0   \n",
       "1682          0       0          0          0         0       0  ...       0   \n",
       "\n",
       "        Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western    year  \\\n",
       "itemid                                                                      \n",
       "1             0        0        0       0         0    0        0  1995.0   \n",
       "2             0        0        0       0         1    0        0  1995.0   \n",
       "3             0        0        0       0         1    0        0  1995.0   \n",
       "4             0        0        0       0         0    0        0  1995.0   \n",
       "5             0        0        0       0         1    0        0  1995.0   \n",
       "...         ...      ...      ...     ...       ...  ...      ...     ...   \n",
       "1678          0        0        0       0         0    0        0  1998.0   \n",
       "1679          0        0        1       0         1    0        0  1998.0   \n",
       "1680          0        0        1       0         0    0        0  1998.0   \n",
       "1681          0        0        0       0         0    0        0  1994.0   \n",
       "1682          0        0        0       0         0    0        0  1996.0   \n",
       "\n",
       "        normalized_year  \n",
       "itemid                   \n",
       "1              0.393860  \n",
       "2              0.393860  \n",
       "3              0.393860  \n",
       "4              0.393860  \n",
       "5              0.393860  \n",
       "...                 ...  \n",
       "1678           0.604334  \n",
       "1679           0.604334  \n",
       "1680           0.604334  \n",
       "1681           0.323703  \n",
       "1682           0.464018  \n",
       "\n",
       "[1682 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las filas con ítems que no tienen información de año\n",
    "\n",
    "df_items.dropna(subset=['normalized_year'], inplace=True)\n",
    "df_items = df_items.reset_index()\n",
    "df = df[df['itemid'].isin(df_items['itemid'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "contenido = df_items[['Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', \\\n",
    "                      'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western', \\\n",
    "                      'normalized_year']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos PCA20 para generar una representación latente de dimensión 5\n",
    "\n",
    "pca20 = PCA(n_components=5).fit_transform(contenido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos un diccionario {itemid: vector_latente}\n",
    "\n",
    "item_feats = dict(zip(df_items['itemid'], pca20.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_user = ['userid', 'age', 'gender', 'occupation', 'zip_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv(f'{dir_train}/u.user',\n",
    "                        sep='|',\n",
    "                        index_col=0,\n",
    "                        names = columns_user,\n",
    "                        header=None,\n",
    "                        encoding='latin-1')\n",
    "\n",
    "df_users = df_users.reset_index()\n",
    "df_items = df_items.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diversidad de Ziegler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de la Diversidad de Ziegler es calcular la similaridad entre todos los elementos de una lista de recomendación. Mientras menor sea la similaridad total dentro de una lista, más diversa es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos un diccionario {(item1, item2): Distancia} Para evitar calcular la misma distancia más de una vez\n",
    "\n",
    "dist_dict = dict()\n",
    "\n",
    "def similarity(rec):\n",
    "    s = 0\n",
    "    for m in rec:\n",
    "        s += similarity_i(m, rec)\n",
    "    return s/2\n",
    "\n",
    "def similarity_i(m, rec):\n",
    "    s = 0\n",
    "    if len(rec) <= 1:\n",
    "        return 0\n",
    "    for m2 in rec:\n",
    "        if m != m2:\n",
    "            s += (1 - distance(m, m2))\n",
    "    return s\n",
    "\n",
    "def distance(i1, i2):\n",
    "    if (i1, i2) in dist_dict.keys():\n",
    "        return dist_dict[(i1, i2)]\n",
    "    dist = pairwise_distances(np.array(item_feats[i1]).reshape(1,-1), np.array(item_feats[i2]).reshape(1,-1), metric='cosine')\n",
    "    dist_dict[(i1, i2)] = dist\n",
    "    dist_dict[(i2, i1)] = dist\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novedad de Vargas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vargas y Castell (2011) definen un concepto de novedad basado en la probabilidad de que el usuario no haya visto ese ítem anteriormente. Esta probabilidad la plantean como el logaritmo de la popularidad inversa del ítem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity(iid):\n",
    "    l = len(df[df['itemid'] == iid])\n",
    "    return l/len(df)\n",
    "\n",
    "dict_novelty = defaultdict(lambda: -100)\n",
    "def novelty(rec):\n",
    "    tot = 0\n",
    "    for iid in rec:\n",
    "        if dict_novelty[iid] == -100:\n",
    "            novl = novelty_i(iid)\n",
    "            dict_novelty[iid] = novl\n",
    "            tot += novl\n",
    "        else:\n",
    "            tot += dict_novelty[iid]\n",
    "    return tot/len(rec)\n",
    "\n",
    "def novelty_i(iid):\n",
    "    return -1*np.log2(popularity(iid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicion de métricas (No editar)\n",
    "# Obtenido de https://gist.github.com/bwhite/3726239\n",
    "\n",
    "def _precision_at_k(r, k):\n",
    "    assert k >= 1\n",
    "    r = np.asarray(r)[:k] != 0\n",
    "    if r.size != k:\n",
    "        raise ValueError('Relevance score length < k')\n",
    "    return np.mean(r)\n",
    "\n",
    "def average_precision(r):\n",
    "    r = np.asarray(r) != 0\n",
    "    out = [_precision_at_k(r, k + 1) for k in range(r.size) if r[k]]\n",
    "    if not out:\n",
    "        return 0.\n",
    "    return np.mean(out)\n",
    "\n",
    "def mean_average_precision(rs):\n",
    "    return np.mean([average_precision(r) for r in rs])\n",
    "\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return np.sum(np.subtract(np.power(2, r), 1) / np.log2(np.arange(2, r.size + 2)))\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k):\n",
    "    idcg = dcg_at_k(sorted(r, reverse=True), k)\n",
    "\n",
    "    if not idcg:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k) / idcg\n",
    "\n",
    "# Define function to obtain nDCG scores\n",
    "def get_ndcg(surprise_predictions, k_highest_scores=None):\n",
    "    \"\"\"\n",
    "    Calculates the ndcg (normalized discounted cumulative gain) from surprise predictions, using sklearn.metrics.ndcg_score and scipy.sparse\n",
    "\n",
    "    Parameters:\n",
    "    surprise_predictions (List of surprise.prediction_algorithms.predictions.Prediction): list of predictions\n",
    "    k_highest_scores (positive integer): Only consider the highest k scores in the ranking. If None, use all.\n",
    "\n",
    "    Returns:\n",
    "    float in [0., 1.]: The averaged NDCG scores over all recommendations\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.metrics import ndcg_score\n",
    "    from scipy import sparse\n",
    "\n",
    "    uids = [int(p.uid) for p in surprise_predictions ]\n",
    "    iids = [int(p.iid) for p in surprise_predictions ]\n",
    "    r_uis = [p.r_ui for p in surprise_predictions ]\n",
    "    ests = [p.est for p in surprise_predictions ]\n",
    "\n",
    "    assert(len(uids) == len(iids) == len(r_uis) == len(ests) )\n",
    "\n",
    "    sparse_preds = sparse.coo_matrix( (ests, (uids , iids )) )\n",
    "    sparse_vals = sparse.coo_matrix( (r_uis, (uids , iids )) )\n",
    "\n",
    "    dense_preds = sparse_preds.toarray()\n",
    "    #print(dense_preds)\n",
    "    dense_vals = sparse_vals.toarray()\n",
    "\n",
    "    return ndcg_score(y_true= dense_vals , y_score= dense_preds, k=k_highest_scores, ignore_ties=True)\n",
    "\n",
    "def get_AUC_at_k(model, k):\n",
    "\n",
    "    auc = implicit.evaluation.AUC_at_k(model,\n",
    "                                       user_item_matrix,\n",
    "                                       user_item_matrix_test,\n",
    "                                       show_progress=False,\n",
    "                                       K=k\n",
    "                                    )\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylqxKuF6tsX2"
   },
   "source": [
    "### Actividad 1: Cálculo de métricas Beyond-Accuracy.\n",
    "\n",
    "* Elija y entrene 3 métodos vistos en clases (pueden ser cualquiera de los métodos de recomendación personalizada, ya sea de feedback implícito, explícito, híbrido, etc.)\n",
    "* Elija 2 métricas de evaluación tradicional (pueden ser métricas de error, ranking, precision, etc.)\n",
    "* Evalúe los métodos entrenados y genere una tabla que contenga los valores de las dos métricas elegidas por usted y las métricas de diversidad y novedad proporcionadas.\n",
    "* Para las métricas Beyond-Accuracy, evalúe los sistemas con Novelty@k y Diversity@k con k = 10, 15, 20. Donde k es el largo de las listas de recomendación que se le entregan a los usuarios.\n",
    "\n",
    "Tenga en cuenta los siguientes puntos.\n",
    "\n",
    "* Dependiendo el método que elija, puede que tenga que realizar un pre-procesamiento distinto para los datos. Puede cambiar el dataset df utilizado por una de los splits predeterminados de MovieLens (ux.base). Si utiliza el dataset completo, recuerde generar el split train-test antes de entrenar. Si cambia el archivo, recuerde eliminar el item con el dato de fecha de estreno faltante (como se hizo al comienzo de este cuadernillo).\n",
    "* Las funciones de métricas Beyond-Accuracy entregadas evalúan una única lista de recomendación. Para evaluar un sistema de recomendación, genere listas de recomendación para todos los usuarios del set de testeo y obtenga el promedio de todos los usuarios.\n",
    "* Recuerde que la función entregada para la diversidad es una métrica de similaridad. Para sus análisis, debe tener en cuenta que un mayor valor implica una menor similaridad.\n",
    "* Las funciones se definieron para recibir los ids de los items según están en el dataframe original (itemid). Tenga cuidado al manejar estos ids para evitar referirse a items equivocados.\n",
    "\n",
    "Concluya a partir de los resultados de la tabla. Discuta por qué podría ser conveniente tener un nivel de Novelty y Diversity alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G14TbCAeuk3G"
   },
   "source": [
    "#### Respuesta:\n",
    "\n",
    "Ingrese su respuesta continuación. Recuerde terminar su respuesta con una celda de texto con sus conclusiones y respuestas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparacion Datos ALS/BPR\n",
    "train_dir = \"ml-100k/u3.base\"\n",
    "test_dir = \"ml-100k/u3.test\"\n",
    "train_file = pd.read_csv(train_dir, sep='\\t', names = ['userid', 'itemid', 'rating', 'timestamp'], header=None)\n",
    "info_cols = [ 'movieid', 'title', 'release_date', 'video_release_date', 'IMDb_URL', \\\n",
    "              'unknown', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', \\\n",
    "              'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', \\\n",
    "              'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western' ]\n",
    "info_file = pd.read_csv('ml-100k/u.item', sep='|', index_col = 0, names = info_cols, header=None, encoding='latin-1')\n",
    "# Cambio los nombres de los archivos para un formato mas familiar\n",
    "\n",
    "df_train = train_file.copy()\n",
    "\n",
    "df_items = info_file.copy()\n",
    "\n",
    "# Si el rating es >= 3 entonces es relevante, si no, 0\n",
    "\n",
    "df_train.rating = [1 if x > 3 else 0 for x in df_train.rating]\n",
    "\n",
    "# Creo los objetos que contendran la informacion de los usuarios e items\n",
    "user_items = {}\n",
    "itemset = set ()\n",
    "\n",
    "# Itero sobre toda el df de entrenamiento y junto en un diccionario el id de un usuario\n",
    "# Con sus items relevantes\n",
    "for row in df_train.itertuples():\n",
    "    if row[3]:\n",
    "        if row[1] not in user_items:\n",
    "            user_items[row[1]] = []\n",
    "\n",
    "        user_items[row[1]].append(row[2])\n",
    "        itemset.add(row[2])\n",
    "\n",
    "# Cambio el formato del set de items para poder ordenarlo\n",
    "itemset = np.sort(list(itemset))\n",
    "\n",
    "# Creo una matriz de ceros con las dimensiones UxI\n",
    "sparse_matrix = np.zeros((len(user_items), len(itemset)))\n",
    "\n",
    "# Cambio los valores de los ceros por el de 1 cuando el item es relevante\n",
    "for i, items in enumerate(user_items.values()):\n",
    "    sparse_matrix[i] = np.isin(itemset, items, assume_unique = True).astype(int)\n",
    "\n",
    "# Crear una matriz comprimida que utilice menos carga computacional\n",
    "user_item_matrix = sparse.csr_matrix(sparse_matrix)\n",
    "\n",
    "# Creo un diccionario con los ids de usuarios e items\n",
    "\n",
    "user_ids = {key: i for i, key in enumerate(user_items.keys())}\n",
    "items_ids = {key: i for i, key in enumerate(itemset)}\n",
    "\n",
    "# Cargamos el dataser de prueba\n",
    "df_test = pd.read_csv(f'{test_dir}',\n",
    "                      sep='\\t',\n",
    "                      names=['userid', 'itemid', 'rating', 'timestamp'],\n",
    "                      header=None)\n",
    "\n",
    "\n",
    "# rating >= 3 es relevante (1) y rating menor a 3 es no relevante (0)\n",
    "df_test.rating = [1 if x >=3 else 0 for x in df_test.rating ]\n",
    "\n",
    "\n",
    "user_items_test = {}\n",
    "\n",
    "for row in df_test.itertuples():\n",
    "    if row[3] and row[1] in user_items:\n",
    "        if row[1] not in user_items_test:\n",
    "            user_items_test[row[1]] = []\n",
    "\n",
    "        user_items_test[row[1]].append(row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 10 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90361b07d4ee498bbeaa372980d28fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1058ff61091a4cd88dacabec7b61fb66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modelo ALS\n",
    "# ALS\n",
    "f = 15\n",
    "rg = 0.01\n",
    "model_als = implicit.als.AlternatingLeastSquares(factors=f, regularization=rg)\n",
    "model_als.fit(user_item_matrix)\n",
    "#als_mmap, als_ndcg, als_precision = evaluate_model2(model_als, 10)\n",
    "\n",
    "# BPR\n",
    "f = 70\n",
    "it = 50\n",
    "model_bpr = implicit.bpr.BayesianPersonalizedRanking(factors=f, iterations=it)\n",
    "model_bpr.fit(user_item_matrix)\n",
    "#bpr_mmap, bpr_ndcg, bpr_precision = evaluate_model2(model_bpr, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users: 943, num_items: 1681.\n",
      "AUC score: 0.8629933595657349\n",
      "Precision at 20: 0.1768822818994522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modelo light FM\n",
    "dataset = Dataset()\n",
    "# Se ajusta el objeto dataset con la información de usuarios e ítems\n",
    "\n",
    "dataset.fit(users=df['userid'],\n",
    "            items=df['itemid'])\n",
    "\n",
    "# A partir de esto, podemos determinar fácilmente el número de usuarios e ítems únicos.\n",
    "num_users, num_items = dataset.interactions_shape()\n",
    "print(f'Num users: {num_users}, num_items: {num_items}.')\n",
    "(interactions, weights) = dataset.build_interactions(df.iloc[:, 0:3].values)\n",
    "train_interactions, test_interactions = cross_validation.random_train_test_split(\n",
    "    interactions, test_percentage=0.25)\n",
    "\n",
    "model1 = LightFM(no_components=15, loss='logistic')\n",
    "model1.fit(interactions=train_interactions, epochs=5)\n",
    "\n",
    "print(f'AUC score: {auc_score(model1, test_interactions, train_interactions=train_interactions).mean()}')\n",
    "print(f'Precision at 20: {precision_at_k(model1, test_interactions, train_interactions=train_interactions, k=20).mean()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo BPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKHFLAfIusZm"
   },
   "source": [
    "### Actividad 2: Accuracy vs. Beyond-Accuracy.\n",
    "\n",
    "* Elija uno de los métodos que utilizó en la actividad 1 (no necesariamente tiene que ser el que entregó mejores resultados) y entrénelo modificando los valores de sus hiperparámetros.\n",
    "* Elija una de las métricas tradicionales que utilizó en la actividad 1 y evalúe los modelos entrenados con distintos hiperparámetros en esta métrica en Accuracy@20 y Novelty@20.\n",
    "* Genere gráficos que comparen el valor de la métrica tradicional (eje x) con las métrica beyond-accuracy (eje y). Por ejemplo, un gráfico de recall-Accuracy y otro de recall-Novelty.\n",
    "* Cada gráfico debe tener al menos 5 puntos evaluados.\n",
    "\n",
    "Concluya a partir de estos gráficos, discutiendo la forma de estos y lo que esto implica al generar un modelo recomendador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Respuesta:\n",
    "\n",
    "Ingrese su respuesta continuación. Recuerde terminar su respuesta con una celda de texto con sus conclusiones y respuestas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actividad 3: Beyond-Accuracy vs. Beyond-Accuracy\n",
    "\n",
    "Repita el procedimiento de la actividad 2, pero esta vez genere un gráfico de Novelty@20 Vs. Diversity@20.\n",
    "\n",
    "A partir de este gráfico, concluya la correlación entre estas dos métricas y explique en sus palabras por qué cree que se da este efecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Respuesta:\n",
    "\n",
    "Ingrese su respuesta continuación. Recuerde terminar su respuesta con una celda de texto con sus conclusiones y respuestas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sección 2 - Recomendación secuencial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección utilizaremos Gru4Rec, para entrenar un modelo de recomendación secuencial basado en sesiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de Gru4Rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguiremos el mismo procedimiento utilizado en el tutorial de Gru4Rec para entrenar el modelo. Este proceso puede llegar a tomar más de 40 minutos, pero solo se debe realizar una vez, ya que los archivos generados se guardan en la carpeta en la que se está corriendo el cuadernillo, por lo que se recomienda ejecutar el código con anticipación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: py7zr in c:\\users\\alfi9\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.20.6)\n",
      "Requirement already satisfied: texttable in c:\\users\\alfi9\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from py7zr) (1.6.7)\n",
      "Requirement already satisfied: pycryptodomex>=3.6.6 in c:\\users\\alfi9\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from py7zr) (3.18.0)\n",
      "Requirement already satisfied: pyzstd>=0.14.4 in c:\\users\\alfi9\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from py7zr) (0.15.9)\n",
      "Requirement already satisfied: pyppmd<1.1.0,>=0.18.1 in c:\\users\\alfi9\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from py7zr) (1.0.0)\n",
      "Requirement already satisfied: pybcj>=0.6.0 in c:\\users\\alfi9\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from py7zr) (1.0.1)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in c:\\users\\alfi9\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from py7zr) (0.2.3)\n",
      "Requirement already satisfied: brotli>=1.0.9 in c:\\users\\alfi9\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from py7zr) (1.0.9)\n",
      "Requirement already satisfied: inflate64>=0.3.1 in c:\\users\\alfi9\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from py7zr) (0.3.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\alfi9\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from py7zr) (5.9.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\alfi9\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\alfi9\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install py7zr\n",
    "!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/hidasib/GRU4Rec_PyTorch_Official --single-branch src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarga del dataset. Esto puede tomar hasta ~40 minutos, pero solo se debe realizar una vez\n",
    "\n",
    "!curl https://s3-eu-west-1.amazonaws.com/yc-rdata/yoochoose-data.7z --output data.7z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py7zr import unpack_7zarchive\n",
    "import shutil\n",
    "\n",
    "shutil.register_unpack_format('7zip', ['.7z'], unpack_7zarchive)\n",
    "shutil.unpack_archive('data.7z', './rsc15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Impotante:** Es posible que al ejecutar el código, se encuentren con el error '*IndexError: tensors used as indices must be long, byte or bool tensors*'. Para arreglar este error, deben modificar la línea 23 del archivo evaluation.py por:\n",
    "\n",
    "tscores = torch.diag(oscores[out_idxs.long()])\n",
    "\n",
    "En el tutorial Gru4Rec podrán encontrar una explicación paso a paso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = './rsc15/'\n",
    "dst_path   = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(src_path, dst_path):\n",
    "    data = pd.read_csv(src_path + 'yoochoose-clicks.dat', sep=',', header=None, usecols=[0,1,2], dtype={0:np.int32, 1:str, 2:np.int64})\n",
    "    data.columns = ['SessionId', 'TimeStr', 'ItemId']\n",
    "\n",
    "    # Convertimos el Timestamp en un objeto datetime\n",
    "    data['Time'] = data.TimeStr.apply(lambda x: dt.datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%fZ').timestamp())\n",
    "    del(data['TimeStr'])\n",
    "\n",
    "    # Tomamos las sesiones de largo > 1\n",
    "    session_lengths = data.groupby('SessionId').size()  \n",
    "    data = data[np.in1d(data.SessionId, session_lengths[session_lengths>1].index)]\n",
    "\n",
    "    # Filtramos los items que aparecen menos de 5 veces.\n",
    "    item_supports = data.groupby('ItemId').size()\n",
    "    data = data[np.in1d(data.ItemId, item_supports[item_supports>=5].index)]\n",
    "\n",
    "    # Volvemos a filtrar las sesiones de largo 1\n",
    "    session_lengths = data.groupby('SessionId').size()\n",
    "    data = data[np.in1d(data.SessionId, session_lengths[session_lengths>=2].index)]\n",
    "\n",
    "    # Vamos a definir el set de testeo como todas las interacciones ocurridas el último día.\n",
    "    tmax = data.Time.max()\n",
    "    session_max_times = data.groupby('SessionId').Time.max()\n",
    "\n",
    "    session_train = session_max_times[session_max_times < tmax-86400].index\n",
    "    train = data[np.in1d(data.SessionId, session_train)]\n",
    "\n",
    "    session_test = session_max_times[session_max_times >= tmax-86400].index\n",
    "    test = data[np.in1d(data.SessionId, session_test)]\n",
    "    test = test[np.in1d(test.ItemId, train.ItemId)]\n",
    "    tslength = test.groupby('SessionId').size()\n",
    "    test = test[np.in1d(test.SessionId, tslength[tslength>=2].index)]\n",
    "    print('Test set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(test), test.SessionId.nunique(), test.ItemId.nunique()))\n",
    "    test.to_csv(dst_path + 'test.tsv', sep='\\t', index=False)\n",
    "\n",
    "    # Validation: Vamos a usar el penúltimo día para el set de validación\n",
    "    tmax = train.Time.max()\n",
    "    session_max_times = train.groupby('SessionId').Time.max()\n",
    "    session_train = session_max_times[session_max_times < tmax-86400].index\n",
    "    session_valid = session_max_times[session_max_times >= tmax-86400].index\n",
    "\n",
    "    train_tr = train[np.in1d(train.SessionId, session_train)]\n",
    "    valid = train[np.in1d(train.SessionId, session_valid)]\n",
    "    valid = valid[np.in1d(valid.ItemId, train_tr.ItemId)]\n",
    "    tslength = valid.groupby('SessionId').size()\n",
    "    valid = valid[np.in1d(valid.SessionId, tslength[tslength>=2].index)]\n",
    "    print('Validation set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(valid), valid.SessionId.nunique(), valid.ItemId.nunique()))\n",
    "    valid.to_csv(dst_path + 'validation.tsv', sep='\\t', index=False)\n",
    "\n",
    "\n",
    "    print('Train set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(train_tr), train_tr.SessionId.nunique(), train_tr.ItemId.nunique()))\n",
    "    train_tr.to_csv(dst_path + 'train.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process(src_path, dst_path)  # Toma ~ 10 minutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fraction(df, fraction, prefix=\"train\", path=\"./data/\"):\n",
    "    \n",
    "    length = len(df['ItemId'])\n",
    "    first_session = df.iloc[length - length//fraction].SessionId # Se toma el Id de la sesión que está en la fracción deseada\n",
    "    df = df.loc[df['SessionId'] >= first_session] # Se guardan únicamente las sesiones cuyo Id sea mayor al Id encontrado\n",
    "    \n",
    "    # Nota: Este procedimiento sólo funciona correctamente si el dataset está ordenado según SessionId\n",
    "    \n",
    "    itemids = df['ItemId'].unique()\n",
    "    n_items = len(itemids)\n",
    "\n",
    "    print('Fractioned data set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(df), df.SessionId.nunique(), df.ItemId.nunique()))\n",
    "    filename = path + '{}_{}.tsv'.format(prefix, fraction)\n",
    "    df.to_csv(filename, sep='\\t', index=False)\n",
    "    print(\"Saved as {}\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para el propósito de esta demo, utilizamos una fracción del dataset de entrenamiento.\n",
    "fraction = 64\n",
    "train = pd.read_csv(dst_path + 'train.tsv', sep='\\t', dtype={'ItemId':np.int64})\n",
    "train_fraction(train, fraction)\n",
    "train_frac = pd.read_csv(dst_path + 'train_64.tsv', sep='\\t', dtype={'ItemId':np.int64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/run.py ./data/train_64.tsv -t ./data/test.tsv -m 1 5 10 20 -ps layers=100,batch_size=32,dropout_p_embed=0.1,dropout_p_hidden=0,learning_rate=0.1,momentum=0,n_sample=2048,sample_alpha=0.75,bpreg=0,logq=1,loss=cross-entropy,constrained_embedding=True,elu_param=0,n_epochs=200 -d cuda:0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actividad 4: Recomendación en base a sesiones.\n",
    "\n",
    "Reporte los resultados del entrenamiento, los valores de Recall y MRR obtenidos.\n",
    "Explique, en sus palabras, el desafío de recomendación en base a sesiones. Cómo difiere de los desafíos que hemos visto hasta ahora, y cómo se evalúa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Respuesta:\n",
    "\n",
    "Ingrese su respuesta continuación. Recuerde terminar su respuesta con una celda de texto con sus conclusiones y respuestas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actividad 5: Análisis de relevancia de secuencia.\n",
    "\n",
    "Gru4Rec, al ser un recomendador secuencial, utiliza la información de la secuencia de interacciones del usuario para predecir el siguiente elemento. En este ejercicio veremos si el orden en que el usuario interactuó con los ítems realmente influye en el rendimiento de Gru4Rec.\n",
    "\n",
    "Para testear esto, vamos a modificar la base de datos, cambiando el orden en que los usuarios interactuaron con los items en el set de entrenamiento. Para lograr esto, usted simplemente debe:\n",
    "\n",
    "* Modificar la columna 'Time' del dataframe 'train_frac' con tal de que el orden en que los usuarios interactuaron con los items sea distinto al original. Esto lo puede lograr de distintas formas; asignándole un valor aleatorio a la columna Time, invirtiéndo los valores de Time en el dataframe, etc.\n",
    "* Importante: Solo modifique el orden en que los usuarios interactuaron con los ítems. No debe agregar, eliminar ni intercambiar los ítems que fueron vistos por cada usuario. Cada usuario debe haber interactuado con exactamente los mismos items con los que interactuó originalmente, pero en un orden diferente.\n",
    "* Guarde el dataframe en un archivo .tsv.\n",
    "* Entrene el modelo Gru4Rec sobre su nuevo dataset. Todos los hiperparámetros deben ser los mismos que en el entrenamiento original, para que este sea el único cambio.\n",
    "\n",
    "Explique su estrategia de modificación del dataset y reporte los resultados, tanto de recall como de MRR y compárelos con los resultados del dataset original. Convluya a partir de esto la importancia del orden de las interacciones en Gru4Rec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Respuesta:\n",
    "\n",
    "Ingrese su respuesta continuación. Recuerde terminar su respuesta con una celda de texto con sus conclusiones y respuestas."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
