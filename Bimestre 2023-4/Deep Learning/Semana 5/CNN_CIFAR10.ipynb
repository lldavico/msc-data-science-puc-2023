{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_layers(cfg):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "\n",
    "            layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(3* 32 * 32, 480)\n",
    "        self.fc2 = nn.Linear(480, 240)\n",
    "        self.fc3 = nn.Linear(240, 120)\n",
    "        self.fc4 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Vgg(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = make_layers(cfg)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadCIFAR10(batch_size, use_data_augmentation, donwload=True):\n",
    "    if use_data_augmentation:\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "        train_transform = transforms.Compose([\n",
    "                            transforms.RandomHorizontalFlip(),\n",
    "                            transforms.RandomCrop(32, 4),\n",
    "                            transforms.ToTensor(),\n",
    "                            normalize,\n",
    "                        ])\n",
    "        test_transform = transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            normalize,\n",
    "                        ])\n",
    "    else:\n",
    "        train_transform = transforms.Compose( \n",
    "            [transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        test_transform = train_transform\n",
    "\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=donwload, transform=train_transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=donwload, transform=test_transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    return trainloader, testloader\n",
    "\n",
    "\n",
    "def GetPrecision(net, dataloader, device, criterion):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            # images, labels = data\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss += criterion(outputs, labels) \n",
    "    return loss, 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parámetros \n",
    "batch_size = 64\n",
    "weight_decay = 0.0001   # Factor para la regularización L2\n",
    "learning_rate = 0.0001\n",
    "use_data_augmentation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acá hay que descomentar la red que se quiera usar\n",
    "# net = MLP()\n",
    "# net = SimpleCNN()\n",
    "net = Vgg([64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']) # VGG-11\n",
    "# net = Vgg([64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']) # VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el set de entrenamiento y test\n",
    "trainloader, testloader = LoadCIFAR10(batch_size, use_data_augmentation, donwload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Vgg(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('mps')\n",
    "print(device)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos la función de pérdida y el optimizador.\n",
    "# ADAM incluye internamente un regularizador L2 y su factor es el 'weight_decay'\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 1. Train loss: 27470.992. Test loss: 32133.564. Train acc: 80.75. Test acc: 78.33\n",
      "Ep. 2. Train loss: 24386.395. Test loss: 29366.170. Train acc: 83.04. Test acc: 79.86\n",
      "Ep. 3. Train loss: 23755.852. Test loss: 29054.002. Train acc: 83.35. Test acc: 80.37\n",
      "Ep. 4. Train loss: 21992.410. Test loss: 27676.531. Train acc: 84.81. Test acc: 81.48\n",
      "Ep. 5. Train loss: 21184.656. Test loss: 28039.496. Train acc: 85.27. Test acc: 80.56\n",
      "Ep. 6. Train loss: 18032.859. Test loss: 25399.078. Train acc: 87.65. Test acc: 82.74\n",
      "Ep. 7. Train loss: 17733.602. Test loss: 26362.535. Train acc: 87.59. Test acc: 82.58\n",
      "Ep. 8. Train loss: 17074.381. Test loss: 26845.926. Train acc: 88.17. Test acc: 82.45\n",
      "Ep. 9. Train loss: 15911.893. Test loss: 25726.545. Train acc: 89.11. Test acc: 83.04\n",
      "Ep. 10. Train loss: 14752.659. Test loss: 25511.240. Train acc: 89.81. Test acc: 84.09\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Comenzamos el loop de entrenamiento\n",
    "for epoch in range(10): \n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # Torch nos fuerza a indicarle que queremos borrar los gradientes guardados\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    current_epoch = epoch + 1\n",
    "\n",
    "    if (current_epoch % 1) == 0:\n",
    "        # Mostramos estadísticas del aprendizaje (incluyendo rendimiento en train y test)\n",
    "\n",
    "        train_loss, train_performance = GetPrecision(net, trainloader, device, criterion)\n",
    "        test_loss, test_performance = GetPrecision(net, testloader, device, criterion)\n",
    "        \n",
    "        # Nomalizo las funciones de pérdida para que sean comparables entre train y test\n",
    "        # Ocurre que el set de train es 5 veces más grande que el set de test... por eso las multiplico por 5\n",
    "        train_loss *= batch_size\n",
    "        test_loss *= batch_size * 5\n",
    "\n",
    "        print(f'Ep. {current_epoch}. Train loss: {train_loss :.3f}. Test loss: {test_loss :.3f}. Train acc: {train_performance :.2f}. Test acc: {test_performance :.2f}')\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "573546c1eada8c60b27f5300df4435af9ba2007194c80719d45c24c6ea4a493c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
