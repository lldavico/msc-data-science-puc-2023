{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"dair-ai/emotion\") # Esta línea no funciona en Cousera, es para que hagan su descarga en Colab o en su entorno personal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a trabajar con el dataset dair-ai/emotion de Hugging Face. \n",
    "\n",
    "- Usaremos el modelo distilbert-base-uncased para hacer fine-tuning en el dataset y, con esto, poder realizar la clasificación de sentimientos. La estructura del dataset y cómo trabajar con los datos tendrán que investigarla ustedes, pero estoy seguro de que serán capaces =D."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para este proyecto tendrán que investigar y aplicar el uso de los siguientes módulos de HuggingFace\n",
    "- AutoTokenizer o DistilBertTokenizer\n",
    "- AutoConfig o DistilBertConfig\n",
    "- AutoModelForSequenceClassification o DistilBertForSequenceClassification\n",
    "- DataCollatorWithPadding o hacer su propia función collatefn\n",
    "\n",
    "## No es obligatorio usar AutoTokenizer, AutoConfig, etc. Pueden hacerlo de otras formas, como entrenando su propio Tokenizer en su propio modelo y/o vocabulario y de ahí entrenar el Transformer para hacer la clasificación. **Esto es mucho más desafiante, no lo recomiendo si disponen de poco tiempo**. Así que recomiendo que usen las estructuras que ya existen de HuggingFace, para cumplir con la complejidad esperada para el curso.\n",
    "\n",
    "## Les recomiendo fuertemente entrenar en un Google Colab, o en su propia máquina si ya tienen el entorno configurado.\n",
    "\n",
    "La calificación será en torno a métricas conocidas de sklearn:\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "accuracy = accuracy_score(real_labels, predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(real_labels, predictions, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "```\n",
    "score = $(Accuracy + Precision + Recall + F1 Score)/4\n",
    "$\n",
    "\n",
    "Son 5 posibles salidas, un modelo que predice aleatoriamente tendría un 20% de precisión, así que empezaremos con un 50% y subiremos gradualmente hasta el 90%.\n",
    "\n",
    "- 50% = 10/100 pts\n",
    "- 55% = 20/100 pts\n",
    "- 60% = 30/100 pts\n",
    "- 65% = 40/100 pts\n",
    "- 70% = 50/100 pts\n",
    "- 75% = 60/100 pts\n",
    "- 80% = 70/100 pts\n",
    "- 85% = 90/100 pts\n",
    "- 90% = 100/100 pts # Mi algoritmo con pocas modificaciones alcanza el 93%, así que ustedes ¡sí o sí pueden!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importante**\n",
    "Nuevamente, como les he mencionado, es importante que entrenen en un Colab aparte. Para esto, una vez que terminen el entrenamiento, tendrán que guardar los pesos del modelo y cargarlos en el evaluador. Si no saben cómo hacerlo, les recomiendo fuertemente ver el video tutorial sobre esto.\n",
    "\n",
    "Además tambien es necesario que la función collate_fn, sea la que implementarón ustedes o DataCollatorWithPadding sea ejecutada en el archivo con nombre **data_collator**, la instancia del modelo **model**, la función de tokenize **tokenize_function** ( Esto es, la función que se utiliza para definir y llamar el tokenizer para cada 'batch'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respuesta Tarea"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separaremos el dataset entre entrenamiento, test y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"dair-ai/emotion\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 16000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el nombre de nuestro modelo para luego utilizar el tokenizador y el modelo. También, definimos el número de clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'distilbert-base-uncased'\n",
    "num_classes = len(set(train_dataset['label']))\n",
    "num_classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el tokenizador y pasamos los datos a tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una función para tokenizar el texto y luego generar un tensor por cada dato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(dataset):\n",
    "    return tokenizer(dataset['text'], truncation=True)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el device a utilizar. Como estoy en un Mac, la GPU es `mps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, definimos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning del modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenaremos el modelo en base a nuestro dataset de entrenamiento `train_dataset` y validaremos con `val_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos los parámetros para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_path = 'finetuned_model_ldavico'\n",
    "learning_rate = 1e-4\n",
    "per_device_train_batch_size = 32\n",
    "per_device_eval_batch_size = 32\n",
    "num_train_epochs = 5\n",
    "weight_decay = 0.01"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizamos nuestras frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval = eval_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "   output_dir=model_output_path,\n",
    "   learning_rate=learning_rate,\n",
    "   per_device_train_batch_size=per_device_train_batch_size,\n",
    "   per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "   num_train_epochs=num_train_epochs,\n",
    "   weight_decay=weight_decay,\n",
    "   save_strategy=\"epoch\",\n",
    ")\n",
    " \n",
    "trainer = Trainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=tokenized_train,\n",
    "   eval_dataset=tokenized_eval,\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92aa825d91a54d9ba92947524884afc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4023, 'learning_rate': 8e-05, 'epoch': 1.0}\n",
      "{'loss': 0.1469, 'learning_rate': 6e-05, 'epoch': 2.0}\n",
      "{'loss': 0.1033, 'learning_rate': 4e-05, 'epoch': 3.0}\n",
      "{'loss': 0.0704, 'learning_rate': 2e-05, 'epoch': 4.0}\n",
      "{'loss': 0.0367, 'learning_rate': 0.0, 'epoch': 5.0}\n",
      "{'train_runtime': 597.9344, 'train_samples_per_second': 133.794, 'train_steps_per_second': 4.181, 'train_loss': 0.15190772399902344, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2500, training_loss=0.15190772399902344, metrics={'train_runtime': 597.9344, 'train_samples_per_second': 133.794, 'train_steps_per_second': 4.181, 'train_loss': 0.15190772399902344, 'epoch': 5.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportamos los pesos y configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_model_name_path = 'finetuned_model'\n",
    "\n",
    "model.save_pretrained(exported_model_name_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import datasets\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "from pandas import read_csv\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertTokenizer, DataCollatorWithPadding\n",
    "\n",
    "# Cargar tu modelo\n",
    "model = AutoModelForSequenceClassification.from_pretrained(exported_model_name_path, num_labels=num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este dataset ya está cargado arriba\n",
    "#eval_dataset = read_csv('test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acá se utilizó el `test_dataset` procesado de la misma forma que el `eval_dataset`. Además, había corregí la columna llamada `labels` a `label`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4d67477fdf4dee82aad6b3a43c0f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Si hiciste alguno cambio distinto de lo propuesto abajo, cambiar como se procesa el set de testeo para obtener el mismo tipo de datos\n",
    "\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=8, collate_fn=data_collator)\n",
    "model.eval()\n",
    "predictions = []\n",
    "real_labels = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    # Acá si el formato que dejaste los batches es distinto, adecuar funcion\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predicted_labels = torch.argmax(logits, dim=1)\n",
    "    # NO EDITAR    \n",
    "    predictions.extend(predicted_labels.cpu().numpy())\n",
    "    real_labels.extend(batch['labels'].cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.928\n",
      "Precision: 0.9269373615544183\n",
      "Recall: 0.928\n",
      "F1 Score: 0.9272691021082526\n",
      "score:  0.9275516159156678\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "accuracy = accuracy_score(real_labels, predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(real_labels, predictions, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print('score: ', (accuracy + precision + recall + f1) / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "573546c1eada8c60b27f5300df4435af9ba2007194c80719d45c24c6ea4a493c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
